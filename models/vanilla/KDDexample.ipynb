{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Traing on KDD datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EQSNHITWCiUP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import sklearn\n",
        "import io\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5kw4YhFeXsQh"
      },
      "outputs": [],
      "source": [
        "train_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Train.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/merteroglu/NSL-KDD-Network-Instrusion-Detection/master/NSL_KDD_Test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evt7ic2AYwyp",
        "outputId": "f1b5e819-8a55-4844-b3bd-c2155a899f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions of the Training set: (125973, 42)\n",
            "Dimensions of the Test set: (22544, 42)\n"
          ]
        }
      ],
      "source": [
        "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\"]\n",
        "\n",
        "\n",
        "df = pd.read_csv(train_url,header=None, names = col_names)\n",
        "\n",
        "df_test = pd.read_csv(test_url, header=None, names = col_names)\n",
        "\n",
        "print('Dimensions of the Training set:',df.shape)\n",
        "print('Dimensions of the Test set:',df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmYmyCstZ3cQ",
        "outputId": "a65d742d-b67f-40ea-ddfb-e9bba5d9530c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution Training set:\n",
            "normal             67343\n",
            "neptune            41214\n",
            "satan               3633\n",
            "ipsweep             3599\n",
            "portsweep           2931\n",
            "smurf               2646\n",
            "nmap                1493\n",
            "back                 956\n",
            "teardrop             892\n",
            "warezclient          890\n",
            "pod                  201\n",
            "guess_passwd          53\n",
            "buffer_overflow       30\n",
            "warezmaster           20\n",
            "land                  18\n",
            "imap                  11\n",
            "rootkit               10\n",
            "loadmodule             9\n",
            "ftp_write              8\n",
            "multihop               7\n",
            "phf                    4\n",
            "perl                   3\n",
            "spy                    2\n",
            "Name: label, dtype: int64\n",
            "\n",
            "Label distribution Test set:\n",
            "normal             9711\n",
            "neptune            4657\n",
            "guess_passwd       1231\n",
            "mscan               996\n",
            "warezmaster         944\n",
            "apache2             737\n",
            "satan               735\n",
            "processtable        685\n",
            "smurf               665\n",
            "back                359\n",
            "snmpguess           331\n",
            "saint               319\n",
            "mailbomb            293\n",
            "snmpgetattack       178\n",
            "portsweep           157\n",
            "ipsweep             141\n",
            "httptunnel          133\n",
            "nmap                 73\n",
            "pod                  41\n",
            "buffer_overflow      20\n",
            "multihop             18\n",
            "named                17\n",
            "ps                   15\n",
            "sendmail             14\n",
            "rootkit              13\n",
            "xterm                13\n",
            "teardrop             12\n",
            "xlock                 9\n",
            "land                  7\n",
            "xsnoop                4\n",
            "ftp_write             3\n",
            "worm                  2\n",
            "loadmodule            2\n",
            "perl                  2\n",
            "sqlattack             2\n",
            "udpstorm              2\n",
            "phf                   2\n",
            "imap                  1\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Label distribution Training set:')\n",
        "print(df['label'].value_counts())\n",
        "print()\n",
        "print('Label distribution Test set:')\n",
        "print(df_test['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXxFOLRoZ-AW",
        "outputId": "9b1cbea6-44ae-4dc2-b87e-ffc42e7dd962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "Feature 'protocol_type' has 3 categories\n",
            "Feature 'service' has 70 categories\n",
            "Feature 'flag' has 11 categories\n",
            "Feature 'label' has 23 categories\n",
            "\n",
            "Distribution of categories in service:\n",
            "http        40338\n",
            "private     21853\n",
            "domain_u     9043\n",
            "smtp         7313\n",
            "ftp_data     6860\n",
            "Name: service, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Training set:')\n",
        "for col_name in df.columns:\n",
        "    if df[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
        "\n",
        "print()\n",
        "print('Distribution of categories in service:')\n",
        "print(df['service'].value_counts().sort_values(ascending=False).head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd9Iu9agaE7V",
        "outputId": "f0920a72-e5cf-4b26-f1f9-0cfa283e58e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set:\n",
            "Feature 'protocol_type' has 3 categories\n",
            "Feature 'service' has 64 categories\n",
            "Feature 'flag' has 11 categories\n",
            "Feature 'label' has 38 categories\n"
          ]
        }
      ],
      "source": [
        "# Test set\n",
        "print('Test set:')\n",
        "for col_name in df_test.columns:\n",
        "    if df_test[col_name].dtypes == 'object' :\n",
        "        unique_cat = len(df_test[col_name].unique())\n",
        "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "F0L_q4etaHM3",
        "outputId": "a7c14167-e020-400a-9f37-9bced8bee485"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>protocol_type</th>\n",
              "      <th>service</th>\n",
              "      <th>flag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tcp</td>\n",
              "      <td>ftp_data</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>udp</td>\n",
              "      <td>other</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tcp</td>\n",
              "      <td>private</td>\n",
              "      <td>S0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>SF</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  protocol_type   service flag\n",
              "0           tcp  ftp_data   SF\n",
              "1           udp     other   SF\n",
              "2           tcp   private   S0\n",
              "3           tcp      http   SF\n",
              "4           tcp      http   SF"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "categorical_columns=['protocol_type', 'service', 'flag']\n",
        "\n",
        "df_categorical_values = df[categorical_columns]\n",
        "testdf_categorical_values = df_test[categorical_columns]\n",
        "\n",
        "df_categorical_values.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqubRmw1aPS6",
        "outputId": "3620e5ef-b0d4-4a47-9098-2fc3d9ddb19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp']\n",
            "['service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois']\n",
            "['flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
          ]
        }
      ],
      "source": [
        "# protocol type\n",
        "unique_protocol=sorted(df.protocol_type.unique())\n",
        "string1 = 'Protocol_type_'\n",
        "unique_protocol2=[string1 + x for x in unique_protocol]\n",
        "print(unique_protocol2)\n",
        "\n",
        "# service\n",
        "unique_service=sorted(df.service.unique())\n",
        "string2 = 'service_'\n",
        "unique_service2=[string2 + x for x in unique_service]\n",
        "print(unique_service2)\n",
        "\n",
        "\n",
        "# flag\n",
        "unique_flag=sorted(df.flag.unique())\n",
        "string3 = 'flag_'\n",
        "unique_flag2=[string3 + x for x in unique_flag]\n",
        "print(unique_flag2)\n",
        "\n",
        "\n",
        "# put together\n",
        "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
        "\n",
        "\n",
        "#do it for test set\n",
        "unique_service_test=sorted(df_test.service.unique())\n",
        "unique_service2_test=[string2 + x for x in unique_service_test]\n",
        "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-JpZ6qhaTl3",
        "outputId": "2013a906-a376-47ca-e811-7eebdf48c824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  protocol_type   service flag\n",
            "0           tcp  ftp_data   SF\n",
            "1           udp     other   SF\n",
            "2           tcp   private   S0\n",
            "3           tcp      http   SF\n",
            "4           tcp      http   SF\n",
            "--------------------\n",
            "   protocol_type  service  flag\n",
            "0              1       20     9\n",
            "1              2       44     9\n",
            "2              1       49     5\n",
            "3              1       24     9\n",
            "4              1       24     9\n"
          ]
        }
      ],
      "source": [
        "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
        "\n",
        "print(df_categorical_values.head())\n",
        "print('--------------------')\n",
        "print(df_categorical_values_enc.head())\n",
        "\n",
        "# test set\n",
        "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po3OMU32nMEM",
        "outputId": "1074a3b4-199c-4577-a29a-ad4d93ac09d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
            "0         0              1       20     9        491          0     0   \n",
            "1         0              2       44     9        146          0     0   \n",
            "2         0              1       49     5          0          0     0   \n",
            "3         0              1       24     9        232       8153     0   \n",
            "4         0              1       24     9        199        420     0   \n",
            "\n",
            "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
            "0               0       0    0  ...                  25   \n",
            "1               0       0    0  ...                   1   \n",
            "2               0       0    0  ...                  26   \n",
            "3               0       0    0  ...                 255   \n",
            "4               0       0    0  ...                 255   \n",
            "\n",
            "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
            "0                    0.17                    0.03   \n",
            "1                    0.00                    0.60   \n",
            "2                    0.10                    0.05   \n",
            "3                    1.00                    0.00   \n",
            "4                    1.00                    0.00   \n",
            "\n",
            "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
            "0                         0.17                         0.00   \n",
            "1                         0.88                         0.00   \n",
            "2                         0.00                         0.00   \n",
            "3                         0.03                         0.04   \n",
            "4                         0.00                         0.00   \n",
            "\n",
            "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
            "0                  0.00                      0.00                  0.05   \n",
            "1                  0.00                      0.00                  0.00   \n",
            "2                  1.00                      1.00                  0.00   \n",
            "3                  0.03                      0.01                  0.00   \n",
            "4                  0.00                      0.00                  0.00   \n",
            "\n",
            "   dst_host_srv_rerror_rate    label  \n",
            "0                      0.00   normal  \n",
            "1                      0.00   normal  \n",
            "2                      0.00  neptune  \n",
            "3                      0.01   normal  \n",
            "4                      0.00   normal  \n",
            "\n",
            "[5 rows x 42 columns]\n"
          ]
        }
      ],
      "source": [
        "df[categorical_columns] = df[categorical_columns].apply(LabelEncoder().fit_transform)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLoIpo8snsnP",
        "outputId": "9c7ec09b-32cf-4344-f0e7-a64abe21fdd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
            "0         0              1       20     9        491          0     0   \n",
            "1         0              2       44     9        146          0     0   \n",
            "2         0              1       49     5          0          0     0   \n",
            "3         0              1       24     9        232       8153     0   \n",
            "4         0              1       24     9        199        420     0   \n",
            "\n",
            "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
            "0               0       0    0  ...                  25   \n",
            "1               0       0    0  ...                   1   \n",
            "2               0       0    0  ...                  26   \n",
            "3               0       0    0  ...                 255   \n",
            "4               0       0    0  ...                 255   \n",
            "\n",
            "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
            "0                    0.17                    0.03   \n",
            "1                    0.00                    0.60   \n",
            "2                    0.10                    0.05   \n",
            "3                    1.00                    0.00   \n",
            "4                    1.00                    0.00   \n",
            "\n",
            "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
            "0                         0.17                         0.00   \n",
            "1                         0.88                         0.00   \n",
            "2                         0.00                         0.00   \n",
            "3                         0.03                         0.04   \n",
            "4                         0.00                         0.00   \n",
            "\n",
            "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
            "0                  0.00                      0.00                  0.05   \n",
            "1                  0.00                      0.00                  0.00   \n",
            "2                  1.00                      1.00                  0.00   \n",
            "3                  0.03                      0.01                  0.00   \n",
            "4                  0.00                      0.00                  0.00   \n",
            "\n",
            "   dst_host_srv_rerror_rate  label  \n",
            "0                      0.00      0  \n",
            "1                      0.00      0  \n",
            "2                      0.00      1  \n",
            "3                      0.01      0  \n",
            "4                      0.00      0  \n",
            "\n",
            "[5 rows x 42 columns]\n"
          ]
        }
      ],
      "source": [
        "df['label'] = df['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BWQUJiCo5OY",
        "outputId": "a68d081d-2cc2-4060-f1ba-fd8a62ff8c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples of normalized data:\n",
            "tensor([[-1.0000,  0.0000,  0.4203,  0.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5186, -0.9765,\n",
            "          1.0000,  1.0000, -1.0000, -1.0000, -0.9000, -0.8600, -1.0000,  1.0000,\n",
            "         -0.8031, -0.8000, -0.9000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
            "         -1.0000],\n",
            "        [-1.0000,  0.0000,  0.4203, -0.8000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5264, -0.9256,\n",
            "         -1.0000, -1.0000,  1.0000,  1.0000, -0.6800, -0.8800, -1.0000,  1.0000,\n",
            "         -0.8583, -0.8600, -0.8600, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,\n",
            "          1.0000],\n",
            "        [-1.0000,  0.0000,  0.4203,  0.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3503, -0.9648,\n",
            "          1.0000,  1.0000, -1.0000, -1.0000, -0.9000, -0.8800, -1.0000,  1.0000,\n",
            "         -0.9370, -0.9200, -0.9000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
            "         -1.0000],\n",
            "        [-1.0000,  0.0000,  0.4203,  0.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5421, -0.9374,\n",
            "          1.0000,  1.0000, -1.0000, -1.0000, -0.7200, -0.8800, -1.0000,  1.0000,\n",
            "         -0.8898, -0.8800, -0.8600, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
            "         -1.0000],\n",
            "        [-1.0000,  0.0000,  0.4783,  0.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "         -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0568, -0.9100,\n",
            "          1.0000,  1.0000, -1.0000, -1.0000, -0.8200, -0.9000, -1.0000,  1.0000,\n",
            "         -0.8268, -0.8200, -0.9000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000,\n",
            "         -1.0000]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming df is your DataFrame and it has a column 'label' indicating normal (1) and abnormal (0) data\n",
        "# Separate normal and anomaly data\n",
        "normal_data_df = df[df['label'] == 1].drop(columns=['label']).reset_index(drop=True)\n",
        "anomaly_data_df = df[df['label'] == 0].drop(columns=['label']).reset_index(drop=True)\n",
        "\n",
        "# Convert DataFrame to NumPy array\n",
        "normal_data = normal_data_df.values.astype(np.float32)\n",
        "anomaly_data = anomaly_data_df.values.astype(np.float32)\n",
        "\n",
        "# Normalize data to the range [-1, 1] using MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "normal_data = scaler.fit_transform(normal_data)\n",
        "anomaly_data = scaler.transform(anomaly_data)\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "normal_data = torch.tensor(normal_data)\n",
        "anomaly_data = torch.tensor(anomaly_data)\n",
        "\n",
        "# Print a few examples\n",
        "print(\"Examples of normalized data:\")\n",
        "print(normal_data[:5])  # Print the first 5 rows\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "latent_dim = 100\n",
        "learning_rate = 0.0002\n",
        "num_epochs = 100\n",
        "\n",
        "# DataLoader\n",
        "data_loader = torch.utils.data.DataLoader(normal_data, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JnaXfLZqpe05"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_dim):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Linear(img_dim, 128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.disc(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, img_dim):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(256, img_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "sys.path.append('/homes/hp921/y3finalproject')\n",
        "from utils import *\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "save_path = 'savedmodel/'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Setting up TensorBoard\n",
        "writer = SummaryWriter('/homes/hp921/y3finalproject/runs/vanilla_KDD')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ixKNF4apkhP",
        "outputId": "8d5f4698-e4dc-4f39-dff0-411f779520d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using  cuda\n",
            "Epoch: 0, Loss D: 0.5600278973579407, Loss G: 0.7757691144943237, MMD: 0.889597475528717, EMD: 0.3784097120226399, GPU Memory: 329/8192 MiB, GPU Utilization: 4%\n",
            "Epoch [1/1000]  Loss D: 0.5600278973579407, Loss G: 0.7757691144943237\n",
            "Epoch: 1, Loss D: 0.4996947944164276, Loss G: 0.9124688506126404, MMD: 0.624276340007782, EMD: 0.23607543576319462, GPU Memory: 329/8192 MiB, GPU Utilization: 11%\n",
            "Epoch [2/1000]  Loss D: 0.4996947944164276, Loss G: 0.9124688506126404\n",
            "Epoch: 2, Loss D: 0.6413356065750122, Loss G: 0.7315020561218262, MMD: 0.6365139484405518, EMD: 0.2006716600683616, GPU Memory: 329/8192 MiB, GPU Utilization: 6%\n",
            "Epoch [3/1000]  Loss D: 0.6413356065750122, Loss G: 0.7315020561218262\n",
            "Epoch: 3, Loss D: 0.7111449837684631, Loss G: 0.66212397813797, MMD: 0.45910197496414185, EMD: 0.17795410881015833, GPU Memory: 329/8192 MiB, GPU Utilization: 15%\n",
            "Epoch [4/1000]  Loss D: 0.7111449837684631, Loss G: 0.66212397813797\n",
            "Epoch: 4, Loss D: 0.6194382905960083, Loss G: 0.7743422389030457, MMD: 0.5360170006752014, EMD: 0.2865382515393743, GPU Memory: 329/8192 MiB, GPU Utilization: 15%\n",
            "Epoch [5/1000]  Loss D: 0.6194382905960083, Loss G: 0.7743422389030457\n",
            "Epoch: 5, Loss D: 0.6670286059379578, Loss G: 0.7495760917663574, MMD: 0.23298829793930054, EMD: 0.1811722621333036, GPU Memory: 329/8192 MiB, GPU Utilization: 9%\n",
            "Epoch [6/1000]  Loss D: 0.6670286059379578, Loss G: 0.7495760917663574\n",
            "Epoch: 6, Loss D: 0.5551083087921143, Loss G: 0.7965177297592163, MMD: 0.31836163997650146, EMD: 0.1892110142190524, GPU Memory: 329/8192 MiB, GPU Utilization: 11%\n",
            "Epoch [7/1000]  Loss D: 0.5551083087921143, Loss G: 0.7965177297592163\n",
            "Epoch: 7, Loss D: 0.7071207761764526, Loss G: 0.8378610610961914, MMD: 0.6444120407104492, EMD: 0.28197942946458276, GPU Memory: 329/8192 MiB, GPU Utilization: 9%\n",
            "Epoch [8/1000]  Loss D: 0.7071207761764526, Loss G: 0.8378610610961914\n",
            "Epoch: 8, Loss D: 0.5149184465408325, Loss G: 1.0395269393920898, MMD: 0.33953192830085754, EMD: 0.16671476105315147, GPU Memory: 329/8192 MiB, GPU Utilization: 3%\n",
            "Epoch [9/1000]  Loss D: 0.5149184465408325, Loss G: 1.0395269393920898\n",
            "Epoch: 9, Loss D: 0.6348795890808105, Loss G: 0.7102760076522827, MMD: 0.31748634576797485, EMD: 0.18081338783892678, GPU Memory: 329/8192 MiB, GPU Utilization: 12%\n",
            "Epoch [10/1000]  Loss D: 0.6348795890808105, Loss G: 0.7102760076522827\n",
            "Epoch: 10, Loss D: 0.6517854332923889, Loss G: 0.7413750886917114, MMD: 0.2513147294521332, EMD: 0.133518373022969, GPU Memory: 329/8192 MiB, GPU Utilization: 7%\n",
            "Epoch [11/1000]  Loss D: 0.6517854332923889, Loss G: 0.7413750886917114\n",
            "Epoch: 11, Loss D: 0.5481950044631958, Loss G: 0.9029891490936279, MMD: 0.2877098321914673, EMD: 0.13559580281588846, GPU Memory: 329/8192 MiB, GPU Utilization: 12%\n",
            "Epoch [12/1000]  Loss D: 0.5481950044631958, Loss G: 0.9029891490936279\n",
            "Epoch: 12, Loss D: 0.6072753667831421, Loss G: 0.8213264346122742, MMD: 0.2408294379711151, EMD: 0.1433542758165821, GPU Memory: 329/8192 MiB, GPU Utilization: 12%\n",
            "Epoch [13/1000]  Loss D: 0.6072753667831421, Loss G: 0.8213264346122742\n",
            "Epoch: 13, Loss D: 0.5477721691131592, Loss G: 0.7650464773178101, MMD: 0.3014404773712158, EMD: 0.18768784376353448, GPU Memory: 329/8192 MiB, GPU Utilization: 6%\n",
            "Epoch [14/1000]  Loss D: 0.5477721691131592, Loss G: 0.7650464773178101\n",
            "Epoch: 14, Loss D: 0.5804035663604736, Loss G: 0.9040529727935791, MMD: 0.5683255791664124, EMD: 0.2775829476417928, GPU Memory: 329/8192 MiB, GPU Utilization: 10%\n",
            "Epoch [15/1000]  Loss D: 0.5804035663604736, Loss G: 0.9040529727935791\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m lossD \u001b[38;5;241m=\u001b[39m (lossD_real \u001b[38;5;241m+\u001b[39m lossD_fake) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     27\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 28\u001b[0m \u001b[43mlossD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m optimizer_D\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Train Generator\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"using \", device)\n",
        "\n",
        "# Define your models, optimizer, and loss function\n",
        "generator = Generator(latent_dim, normal_data.shape[1]).to(device)\n",
        "discriminator = Discriminator(normal_data.shape[1]).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):  # Reduced number of epochs for faster trials\n",
        "    for batch_idx, real_data in enumerate(data_loader):\n",
        "        real = real_data.to(device)\n",
        "        noise = torch.randn(real.size(0), latent_dim).to(device)\n",
        "        fake = generator(noise)\n",
        "\n",
        "        # Train Discriminator\n",
        "        disc_real = discriminator(real)\n",
        "        disc_fake = discriminator(fake.detach())\n",
        "\n",
        "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "        lossD = (lossD_real + lossD_fake) / 2\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        lossD.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        output = discriminator(fake)\n",
        "        lossG = criterion(output, torch.ones_like(output))\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        lossG.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    # Calculate MMD and EMD scores\n",
        "    mmd_score = compute_mmd(real, fake)\n",
        "    emd_score = compute_emd(real, fake)\n",
        "\n",
        "    # Get GPU usage\n",
        "    memory_used, memory_total, utilization = get_gpu_usage()\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss D: {lossD.item()}, Loss G: {lossG.item()}, MMD: {mmd_score}, EMD: {emd_score}, GPU Memory: {memory_used}/{memory_total} MiB, GPU Utilization: {utilization}%\")\n",
        "    # Log losses and scores to TensorBoard\n",
        "    writer.add_scalar('Loss/Discriminator', lossD.item(), epoch)\n",
        "    writer.add_scalar('Loss/Generator', lossG.item(), epoch)\n",
        "    writer.add_scalar('Score/MMD', mmd_score, epoch)\n",
        "    writer.add_scalar('Score/EMD', emd_score, epoch)\n",
        "    writer.add_scalar('GPU/Memory_Used', memory_used, epoch)\n",
        "    writer.add_scalar('GPU/Memory_Total', memory_total, epoch)\n",
        "    writer.add_scalar('GPU/Utilization', utilization, epoch)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/1000]  Loss D: {lossD.item()}, Loss G: {lossG.item()}')\n",
        "\n",
        "\n",
        "\n",
        "# Save final model checkpoints\n",
        "torch.save(generator.state_dict(), f'{save_path}generator_final.pth')\n",
        "torch.save(discriminator.state_dict(), f'{save_path}discriminator_final.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUkslEFNOgKV",
        "outputId": "3c863a0f-7f38-4c9b-b196-3fdbfd95bd6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on normal data: 0.7461\n",
            "Accuracy on anomaly data: 0.9829\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "generator = Generator(latent_dim, normal_data.shape[1]).to(device)\n",
        "discriminator = Discriminator(normal_data.shape[1]).to(device)\n",
        "\n",
        "# Evaluate discriminator accuracy on normal and anomaly data\n",
        "def evaluate_discriminator(discriminator, data, labels):\n",
        "    with torch.no_grad():\n",
        "        predictions = discriminator(data.to(device)).cpu()\n",
        "        predicted_labels = (predictions > 0.5).float()\n",
        "        accuracy = accuracy_score(labels, predicted_labels)\n",
        "        return accuracy\n",
        "\n",
        "# Prepare labels\n",
        "normal_labels = torch.ones(normal_data.size(0))\n",
        "anomaly_labels = torch.zeros(anomaly_data.size(0))\n",
        "\n",
        "# Evaluate on normal data\n",
        "normal_accuracy = evaluate_discriminator(discriminator, normal_data, normal_labels)\n",
        "print(f'Accuracy on normal data: {normal_accuracy:.4f}')\n",
        "\n",
        "# Evaluate on anomaly data\n",
        "anomaly_accuracy = evaluate_discriminator(discriminator, anomaly_data, anomaly_labels)\n",
        "print(f'Accuracy on anomaly data: {anomaly_accuracy:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
